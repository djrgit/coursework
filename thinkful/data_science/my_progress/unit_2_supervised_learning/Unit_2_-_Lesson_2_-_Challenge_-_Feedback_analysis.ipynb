{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Feedback Analysis\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source of sentiment words data (gathered November 2018):\n",
    " - [http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Citations:\n",
    "   - Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \n",
    "       Proceedings of the ACM SIGKDD International Conference on Knowledge \n",
    "       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \n",
    "       Washington, USA, \n",
    "   - Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \n",
    "       and Comparing Opinions on the Web.\" Proceedings of the 14th \n",
    "       International World Wide Web conference (WWW-2005), May 10-14, \n",
    "       2005, Chiba, Japan.\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and enable the display of plots in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore harmless seaborn warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the positive and negative sentiment word datasets into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_words = 'https://raw.githubusercontent.com/djrgit/coursework/master/thinkful/data_science/my_progress/unit_2_supervised_learning/positive_words.txt'\n",
    "neg_words = 'https://raw.githubusercontent.com/djrgit/coursework/master/thinkful/data_science/my_progress/unit_2_supervised_learning/negative_words.txt'\n",
    "\n",
    "pos = pd.read_csv(pos_words)\n",
    "neg = pd.read_csv(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_words = [pos, neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create variable names for website review datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_amazon = 'https://raw.githubusercontent.com/djrgit/coursework/master/thinkful/data_science/my_progress/unit_2_supervised_learning/amazon_cells_labelled.txt'\n",
    "label_imdb = 'https://raw.githubusercontent.com/djrgit/coursework/master/thinkful/data_science/my_progress/unit_2_supervised_learning/imdb_labelled.txt'\n",
    "label_yelp = 'https://raw.githubusercontent.com/djrgit/coursework/master/thinkful/data_science/my_progress/unit_2_supervised_learning/yelp_labelled.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [label_amazon, label_imdb, label_yelp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to build an initial DataFrame from website reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_site_dataframe(website_reviews):\n",
    "    wr = requests.get(website_reviews).content\n",
    "    df = pd.read_table(io.StringIO(wr.decode('utf-8')), \n",
    "                       delimiter='\\t\\d\\n', header=None, \n",
    "                       engine='python')\n",
    "    df = df[0].str.split(pat='\\t', n=-1, expand=True)\n",
    "    df = df.rename(columns={0: 'review', 1: 'sentiment'})\n",
    "    df = df[['sentiment', 'review']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to add positive and negative sentiment words to the website review DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sent_words_to_df(df, sent_words):\n",
    "    for sent in sent_words:\n",
    "        for word in sent.iloc[:,0]:\n",
    "            df[str(word)] = df['review'].str.lower().str.contains(str(word), regex=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to run a Bernoulli Naive Bayes classifier on a prepped DataFrame with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bernoulli(prepped_df, site):\n",
    "    data = prepped_df.iloc[:,2:]\n",
    "    target = prepped_df['sentiment']\n",
    "\n",
    "    # Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "    # Instantiate our model and store it in a new variable.\n",
    "    bnb = BernoulliNB()\n",
    "\n",
    "    # Fit our model to the data.\n",
    "    bnb.fit(data, target)\n",
    "\n",
    "    # Classify, storing the result in a new variable.\n",
    "    y_pred = bnb.predict(data)\n",
    "\n",
    "    # Display our results.\n",
    "    print(site[site.rfind('/')+1:site.rfind('_')])\n",
    "    print(\"Number of mislabeled points out of a total {} points : {}\".format(data.shape[0], \n",
    "                                                                             (target != y_pred).sum()))\n",
    "    print('Testing on Sample (Accuracy): ' + str(bnb.score(data, target)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the above functions in a data pipeline for all website review datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_cells\n",
      "Number of mislabeled points out of a total 1000 points : 137\n",
      "Testing on Sample (Accuracy): 0.863\n",
      "\n",
      "\n",
      "imdb\n",
      "Number of mislabeled points out of a total 1000 points : 123\n",
      "Testing on Sample (Accuracy): 0.877\n",
      "\n",
      "\n",
      "yelp\n",
      "Number of mislabeled points out of a total 1000 points : 144\n",
      "Testing on Sample (Accuracy): 0.856\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for site in sites:\n",
    "    run_bernoulli(add_sent_words_to_df(build_site_dataframe(site), sent_words), site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
