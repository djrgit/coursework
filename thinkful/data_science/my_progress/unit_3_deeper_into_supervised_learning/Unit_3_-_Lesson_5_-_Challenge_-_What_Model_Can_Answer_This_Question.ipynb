{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3 - Lesson 5 - Challenge - What Model Can Answer This Question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "> Any regression model (KNN, Random Forest, SVM, Neural Network, etc.).  The various tradeoffs of interpretability and model complexity should be taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  You have more features (columns) than rows in your dataset.\n",
    "> PCA / Regularization - Lasso regularization in particular would allow us to discard columns that have a low contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "> Random Forest (feature importance after performing scaling of features) - A scaled and regularized regression model might also give an indication of feature importance by the sizes of its coefficients.  Gradient Boosting also provides a ranking of features with predictive power.  We can perform all of of these analyses and perform ranking comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Implement a filter to “highlight” emails that might be important to the recipient\n",
    "> Naive Bayes Classifier as it deals well with the high dimensionality of the data.  It also avoids overfitting by giving independent probabilities to words or n-grams with the same spelling but different cardinality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  You have 1000+ features.\n",
    "> PCA / Regularization - Lasso / Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.  Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "> Logistic Regression or any other binary classifier (KNN, Neural Netowrks, SVMs, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.  Your dataset dimensions are 982400 x 500\n",
    "> I would apply a dimensionality reduction technique, followed by a model that has low computational cost or parallelization capabilities such as Random Forest or Naive Bayes.  If computational cost is not an important consideration, and I'd like to focus on getting a model that is as accurate as possible I would choose boosting, SVMs, or neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.  Identify faces in an image.\n",
    "> Logistic Regression (Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.  Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "> Decision Tree, if we want high interpretability of the model.  Otherwise, any multi-class classification algorithm will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
